{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backend API Demo\n",
    "\n",
    "This notebook walks through the core features of StreamWeave against the local dev stack:\n",
    "\n",
    "- Prefect pipeline orchestration\n",
    "- rclone data transfers from simulated CIFS instrument shares\n",
    "- Pre- and post-transfer hook system (file filtering, metadata enrichment)\n",
    "- Fine-grained file access control (users, groups, projects)\n",
    "\n",
    "**Prerequisites:** the dev stack must be running at `https://streamweave.local`.\n",
    "See [Local Development](development.md) for setup instructions.\n",
    "\n",
    "This page is a static rendering of a Jupyter Notebook, which you can <a href=\"./backend-demo.ipynb\" download>&#x2913; download </a> to run locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Docker and Docker Compose installed\n",
    "- `uv` installed for Python package management\n",
    "- The repo cloned and the dev stack already running (see [Local Development](development.md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the notebook, start Jupyter from the repo root:\n",
    "\n",
    "```bash\n",
    "cd backend\n",
    "uv sync\n",
    "uv run jupyter lab ../docs/backend-demo.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to bring up the development docker stack and run at least the first few steps of the [local dev deployment](development.md) setup:\n",
    "\n",
    "> First, redirect the `streamweave.local` DNS name to your local machine by adding the following to `/etc/hosts` (macOS/Linux) or `C:\\System32\\drivers\\etc\\hosts` (windows):\n",
    "> \n",
    "> ```\n",
    "> 127.0.0.1 streamweave.local\n",
    "> ```\n",
    "\n",
    "> Then, generate local certificates using the script at `scripts/setup-dev-certs.sh`\n",
    "\n",
    "> Then, from the repository root, run the following to bring up the development stack:\n",
    "> \n",
    "> ```bash\n",
    "> docker compose -f docker-compose.yml -f docker-compose.dev.yml up\n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains helper commands that will be used throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the repo root regardless of where Jupyter was launched from\n",
    "def _find_repo_root():\n",
    "    p = Path.cwd()\n",
    "    while p != p.parent:\n",
    "        if (p / \"docker-compose.yml\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError(\"Could not find repo root (no docker-compose.yml found)\")\n",
    "\n",
    "def _mkcert_ca_cert() -> str:\n",
    "    caroot = subprocess.run(\n",
    "        [\"mkcert\", \"-CAROOT\"], capture_output=True, text=True, check=True\n",
    "    ).stdout.strip()\n",
    "    return str(Path(caroot) / \"rootCA.pem\")\n",
    "\n",
    "REPO_ROOT = _find_repo_root()\n",
    "DEV_COMPOSE = f\"-f {REPO_ROOT}/docker-compose.yml -f {REPO_ROOT}/docker-compose.dev.yml\"\n",
    "MKCERT_CA_CERT = f\"{REPO_ROOT / \"caddy\" / \"certs\" / \"rootCA.pem\"}\"\n",
    "\n",
    "# Dev stack credentials (set in docker-compose.dev.yml)\n",
    "ADMIN_EMAIL = \"admin@example.com\"\n",
    "ADMIN_PASSWORD = \"adminpassword\"\n",
    "\n",
    "BASE_URL = \"https://streamweave.local\"\n",
    "PREFECT_API_URL = \"https://streamweave.local/prefect/api\"\n",
    "\n",
    "_limits = httpx.Limits(max_connections=10, max_keepalive_connections=5, keepalive_expiry=300)\n",
    "client = httpx.Client(base_url=BASE_URL, timeout=30, verify=MKCERT_CA_CERT, limits=_limits)\n",
    "prefect = httpx.Client(base_url=PREFECT_API_URL, timeout=30, verify=MKCERT_CA_CERT, limits=_limits)\n",
    "\n",
    "\n",
    "def pp(resp, n: int | None = None):\n",
    "    \"\"\"Pretty-print a JSON response. Prints first `n` items if given.\"\"\"\n",
    "    try:\n",
    "        data = resp.json()\n",
    "        if n is not None and isinstance(data, list) and len(data) > n:\n",
    "            data = [*data[:n], \"...\"]\n",
    "        print(json.dumps(data, indent=2))\n",
    "    except Exception:\n",
    "        print(f\"HTTP {resp.status_code}: {resp.text}\")\n",
    "\n",
    "def pp_dict(data, n: int | None = None):\n",
    "    \"\"\"Pretty-print a dictionary or list. Prints first `n` items if given.\"\"\"\n",
    "    if n is not None and isinstance(data, list) and len(data) > n:\n",
    "        data = [*data[:n], \"...\"]\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "\n",
    "def run(cmd, **kwargs):\n",
    "    \"\"\"Run a shell command, streaming stdout normally and stderr in yellow.\"\"\"\n",
    "    YELLOW = \"\\033[33m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    with subprocess.Popen(\n",
    "        cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, **kwargs\n",
    "    ) as proc:\n",
    "        def _stream_stderr():\n",
    "            for line in proc.stderr:\n",
    "                print(f\"{YELLOW}{line}{RESET}\", end=\"\", flush=True)\n",
    "        t = threading.Thread(target=_stream_stderr)\n",
    "        t.start()\n",
    "        for line in proc.stdout:\n",
    "            print(line, end=\"\", flush=True)\n",
    "        t.join()\n",
    "    if proc.returncode != 0:\n",
    "        warnings.warn(f\"Command exited with code {proc.returncode}: {cmd}\")\n",
    "    return proc\n",
    "\n",
    "\n",
    "def wait_for_flow_run(flow_run_id: str, timeout: int = 120) -> str:\n",
    "    \"\"\"Wait for a Prefect flow run to complete. Returns the final state type.\"\"\"\n",
    "    terminal_states = (\"COMPLETED\", \"FAILED\", \"CANCELLED\", \"CRASHED\")\n",
    "    print(f\"Waiting for flow run {flow_run_id} to complete...\")\n",
    "    for attempt in range(timeout):\n",
    "        flow_run = prefect.get(f\"/flow_runs/{flow_run_id}\").json()\n",
    "        state = flow_run.get(\"state\", {}).get(\"type\", \"UNKNOWN\")\n",
    "        if state in terminal_states:\n",
    "            print(f\"Flow run finished with state: {state}\")\n",
    "            return state\n",
    "        print(f\"  State: {state} (attempt {attempt + 1}/{timeout})\")\n",
    "        time.sleep(1)\n",
    "    print(f\"Warning: Flow run did not complete within {timeout} seconds\")\n",
    "    return \"TIMEOUT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the dev stack starts the following docker services:\n",
    "\n",
    "| Service | URL | Description |\n",
    "|---|---|---|\n",
    "| `postgres` | — | Application database |\n",
    "| `redis` | — | Prefect cache |\n",
    "| `prefect-postgres` | — | Prefect's internal database |\n",
    "| `prefect-server` | `https://streamweave.local/prefect/` | Prefect UI + API (admin-only, need to login through main StreamWeave URL first) |\n",
    "| `api` | `https://streamweave.local/api/` | StreamWeave FastAPI backend |\n",
    "| `worker` | — | Prefect worker with rclone |\n",
    "| `frontend` | `https://streamweave.local` | StreamWeave vite frontend dev server (hot reload) |\n",
    "| `caddy` | `https://streamweave.local` | HTTPS reverse proxy |\n",
    "| `mailpit` | `https://streamweave.local/mail/` | SMTP catch-all for outgoing emails |\n",
    "| `s3-dev` | `https://streamweave.local/s3/` | S3-compatible dev storage |\n",
    "| `dev-seed` | — | Seeds sample data on startup, then exits |\n",
    "| `instruments-init` | — | One-shot container that copies `sample_data/` into named volumes, then exits |\n",
    "| `samba-instruments` | — | Single Samba server exposing all 4 instrument shares (`nmr`, `hplc`, `ms`, `tem`) on port 4461 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for services to be ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dev-seed` container runs once on startup and populates the database with sample\n",
    "instruments, storage locations, schedules, and hooks. Re-running is safe — existing\n",
    "records are skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API is ready.\n"
     ]
    }
   ],
   "source": [
    "# Check the API for health to make sure services are ready\n",
    "for attempt in range(60):\n",
    "    try:\n",
    "        resp = client.get(\"/health\")\n",
    "        if resp.status_code == 200:\n",
    "            print(\"API is ready.\")\n",
    "            break\n",
    "    except httpx.RequestError:\n",
    "        pass\n",
    "    print(f\"Waiting for API... (attempt {attempt + 1}/60)\")\n",
    "    time.sleep(2)\n",
    "else:\n",
    "    raise RuntimeError(\"API did not become available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                              IMAGE                        COMMAND                  SERVICE             CREATED         STATUS                     PORTS\n",
      "streamweave-api-1                 streamweave-api              \"sh -c 'alembic upgr…\"   api                 9 minutes ago   Up 9 minutes (healthy)     0.0.0.0:8000->8000/tcp, [::]:8000->8000/tcp\n",
      "streamweave-caddy-1               caddy:alpine                 \"caddy run --config …\"   caddy               9 minutes ago   Up 9 minutes               0.0.0.0:80->80/tcp, [::]:80->80/tcp, 0.0.0.0:443->443/tcp, [::]:443->443/tcp\n",
      "streamweave-frontend-1            streamweave-frontend-dev     \"docker-entrypoint.s…\"   frontend            9 minutes ago   Up 9 minutes               \n",
      "streamweave-mailpit-1             axllent/mailpit:latest       \"/mailpit --webroot …\"   mailpit             9 minutes ago   Up 9 minutes (unhealthy)   0.0.0.0:1025->1025/tcp, [::]:1025->1025/tcp\n",
      "streamweave-postgres-1            postgres:16-alpine           \"docker-entrypoint.s…\"   postgres            9 minutes ago   Up 9 minutes (healthy)     0.0.0.0:5432->5432/tcp, [::]:5432->5432/tcp\n",
      "streamweave-prefect-postgres-1    postgres:16-alpine           \"docker-entrypoint.s…\"   prefect-postgres    9 minutes ago   Up 9 minutes (healthy)     5432/tcp\n",
      "streamweave-prefect-server-1      prefecthq/prefect:3-latest   \"/usr/bin/tini -g --…\"   prefect-server      9 minutes ago   Up 9 minutes (healthy)     \n",
      "streamweave-redis-1               redis:7-alpine               \"docker-entrypoint.s…\"   redis               9 minutes ago   Up 9 minutes (healthy)     0.0.0.0:6379->6379/tcp, [::]:6379->6379/tcp\n",
      "streamweave-s3-dev-1              rclone/rclone:latest         \"rclone serve s3 /da…\"   s3-dev              9 minutes ago   Up 9 minutes               \n",
      "streamweave-samba-archive-1       dperson/samba:latest         \"/sbin/tini -- /usr/…\"   samba-archive       9 minutes ago   Up 9 minutes (healthy)     0.0.0.0:445->445/tcp, [::]:445->445/tcp\n",
      "streamweave-samba-instruments-1   dperson/samba:latest         \"/sbin/tini -- /usr/…\"   samba-instruments   9 minutes ago   Up 9 minutes (healthy)     0.0.0.0:4461->445/tcp, [::]:4461->445/tcp\n",
      "streamweave-worker-1              streamweave-worker           \"prefect worker star…\"   worker              9 minutes ago   Up 9 minutes               \n"
     ]
    }
   ],
   "source": [
    "_ = run(\"docker compose ps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check api status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"ok\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Wait for the API to be ready (retries up to 30 seconds)\n",
    "for attempt in range(30):\n",
    "    try:\n",
    "        resp = client.get(\"/health\")\n",
    "        pp(resp)\n",
    "        break\n",
    "    except httpx.RequestError:\n",
    "        print(f\"Waiting for API... (attempt {attempt + 1}/30)\")\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(\"API did not become available within 30 seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected: `{\"status\": \"ok\"}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Prefect UI is accessible at **https://streamweave.local/prefect/** (you must login at https://streamweave.local/ with an admin account first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get an Auth Token\n",
    "\n",
    "The dev stack automatically creates an admin account on startup via `ensure_admin.py`.\n",
    "The default credentials are `admin@example.com` / `adminpassword` and can be overridden\n",
    "with the `ADMIN_EMAIL` and `ADMIN_PASSWORD` environment variables. This cell will also add the token authentication\n",
    "to both the StreamWeave and Prefect API clients so all later calls are authorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token acquired (first 20 chars): eyJhbGciOiJIUzI1NiIs...\n"
     ]
    }
   ],
   "source": [
    "resp = client.post(\"/auth/jwt/login\", data={\"username\": ADMIN_EMAIL, \"password\": ADMIN_PASSWORD})\n",
    "TOKEN = resp.json()[\"access_token\"]\n",
    "AUTH = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "client.headers[\"Authorization\"] = f\"Bearer {TOKEN}\"\n",
    "prefect.headers[\"Authorization\"] = f\"Bearer {TOKEN}\"\n",
    "print(f\"Token acquired (first 20 chars): {TOKEN[:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Seeded Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell just verifies that all of the expected data was initialized by the seed data container. The later cells in this section show the API responses for each data type individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource           Count  Expected    OK\n",
      "----------------------------------------\n",
      "Service accounts       3         3     ✓\n",
      "Storage locations      3         3     ✓\n",
      "Instruments            4         4     ✓\n",
      "Schedules              4         4     ✓\n",
      "Hooks                  3         3     ✓\n",
      "Users                  5         5     ✓\n"
     ]
    }
   ],
   "source": [
    "resources = [\n",
    "    (\"Service accounts\",  client.get(\"/api/service-accounts\").json(), 3),\n",
    "    (\"Storage locations\", client.get(\"/api/storage-locations\").json(), 3),\n",
    "    (\"Instruments\",       client.get(\"/api/instruments\").json(), 4),\n",
    "    (\"Schedules\",         client.get(\"/api/schedules\").json(), 4),\n",
    "    (\"Hooks\",             client.get(\"/api/hooks\").json(), 3),\n",
    "    (\"Users\",             client.get(\"/api/admin/users\").json(), 5),\n",
    "]\n",
    "\n",
    "w = max(len(label) for label, *_ in resources)\n",
    "print(f\"{'Resource':<{w}}  {'Count':>5}  {'Expected':>8}  {'OK':>4}\")\n",
    "print(\"-\" * (w + 23))\n",
    "for label, data, expected in resources:\n",
    "    count = len(data)\n",
    "    ok = \"✓\" if count == expected else \"✗\"\n",
    "    print(f\"{label:<{w}}  {count:>5}  {expected:>8}  {ok:>4}\")\n",
    "    assert len(data) == expected, f\"{label}: expected {expected}, got {len(data)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Instruments\n",
    "\n",
    "Expected: 4 instruments — Bruker AVANCE III 600 MHz NMR, Waters Acquity UPLC-MS,\n",
    "Thermo Orbitrap Exploris 480, and FEI Titan Themis 300 TEM (offline for maintenance, so `enabled` is `false`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"name\": \"Bruker AVANCE III 600 MHz NMR\",\n",
      "    \"description\": \"600 MHz solution NMR for small-molecule and protein characterization\",\n",
      "    \"location\": \"Chemistry Building, Room 102\",\n",
      "    \"pid\": null,\n",
      "    \"cifs_host\": \"samba-instruments\",\n",
      "    \"cifs_share\": \"nmr\",\n",
      "    \"cifs_base_path\": \"/\",\n",
      "    \"service_account_id\": \"bcc726f9-3cc1-4655-b2d2-4c8bdeae85a5\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"transfer_config\": null,\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:43.014426Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:43.014426Z\",\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"ce1b543b-c30f-4f78-bd5b-1c71c292a826\",\n",
      "    \"name\": \"Waters Acquity UPLC-MS\",\n",
      "    \"description\": \"Ultra-performance liquid chromatography with mass spectrometry detection\",\n",
      "    \"location\": \"Analytical Core, Room 210\",\n",
      "    \"pid\": null,\n",
      "    \"cifs_host\": \"samba-instruments\",\n",
      "    \"cifs_share\": \"hplc\",\n",
      "    \"cifs_base_path\": \"/\",\n",
      "    \"service_account_id\": \"ce5286d7-eae3-4317-b4a8-0b81cf88920a\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"transfer_config\": null,\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:43.020413Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:43.020413Z\",\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"d9effe9b-e447-4edb-8b8d-e599a387b615\",\n",
      "    \"name\": \"Thermo Orbitrap Exploris 480\",\n",
      "    \"description\": \"High-resolution Orbitrap mass spectrometer for proteomics\",\n",
      "    \"location\": \"Proteomics Core, Room 315\",\n",
      "    \"pid\": null,\n",
      "    \"cifs_host\": \"samba-instruments\",\n",
      "    \"cifs_share\": \"ms\",\n",
      "    \"cifs_base_path\": \"/\",\n",
      "    \"service_account_id\": \"66d26e17-b795-4253-9012-76d1fb136fb2\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"transfer_config\": null,\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:43.024856Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:43.024856Z\",\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"d7debd3d-407c-4d23-9d69-f89f56d7a11f\",\n",
      "    \"name\": \"FEI Titan Themis 300 TEM\",\n",
      "    \"description\": \"Aberration-corrected transmission electron microscope\",\n",
      "    \"location\": \"Electron Microscopy Facility, Basement\",\n",
      "    \"pid\": null,\n",
      "    \"cifs_host\": \"samba-instruments\",\n",
      "    \"cifs_share\": \"tem\",\n",
      "    \"cifs_base_path\": \"/\",\n",
      "    \"service_account_id\": null,\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"transfer_config\": null,\n",
      "    \"enabled\": false,\n",
      "    \"created_at\": \"2026-03-01T18:50:43.029103Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:43.029103Z\",\n",
      "    \"deleted_at\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(\"/api/instruments\")\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Storage locations\n",
    "\n",
    "Expected: 3 storage locations — **Local POSIX archive** (`/storage/posix-archive`),\n",
    "**S3 dev bucket** (rclone → `s3-dev:9000`), and **Samba archive share** (CIFS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"74ec55b3-03ae-4a25-8e98-848a2334cf1d\",\n",
      "    \"name\": \"Local POSIX archive\",\n",
      "    \"type\": \"posix\",\n",
      "    \"connection_config\": null,\n",
      "    \"base_path\": \"/storage/posix-archive\",\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:42.953840Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:42.953840Z\",\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"bbed3313-5d4d-47b4-a11a-50c23f2ee21e\",\n",
      "    \"name\": \"S3 dev bucket\",\n",
      "    \"type\": \"s3\",\n",
      "    \"connection_config\": {\n",
      "      \"bucket\": \"instruments\",\n",
      "      \"region\": \"us-east-1\",\n",
      "      \"endpoint_url\": \"http://s3-dev:9000\",\n",
      "      \"access_key_id\": \"devkey\",\n",
      "      \"secret_access_key\": \"****\"\n",
      "    },\n",
      "    \"base_path\": \"instruments\",\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:42.959300Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:42.959300Z\",\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"68909814-0d93-43ec-89d3-738f86ee3c26\",\n",
      "    \"name\": \"Samba archive share\",\n",
      "    \"type\": \"cifs\",\n",
      "    \"connection_config\": {\n",
      "      \"host\": \"samba-archive\",\n",
      "      \"share\": \"archive\",\n",
      "      \"domain\": null,\n",
      "      \"username\": \"devuser\",\n",
      "      \"password\": \"****\"\n",
      "    },\n",
      "    \"base_path\": \"/archive\",\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:43.004967Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:43.004967Z\",\n",
      "    \"deleted_at\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(\"/api/storage-locations\")\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Schedules\n",
    "\n",
    "Expected: 4 schedules with non-null `prefect_deployment_id` — the dev seed creates\n",
    "schedules via the API, which triggers Prefect deployment creation automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"8a67bb69-a550-4d1a-b1f1-d51f38f25b10\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"default_storage_location_id\": \"74ec55b3-03ae-4a25-8e98-848a2334cf1d\",\n",
      "    \"cron_expression\": \"0 1 * * *\",\n",
      "    \"prefect_deployment_id\": \"31f59cc3-c9cc-459e-a437-73bb4db689e8\",\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:43.034902Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:43.036988Z\",\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"27b40d23-5d59-4381-b704-83498be8da05\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"default_storage_location_id\": \"bbed3313-5d4d-47b4-a11a-50c23f2ee21e\",\n",
      "    \"cron_expression\": \"0 2 * * *\",\n",
      "    \"prefect_deployment_id\": \"31f59cc3-c9cc-459e-a437-73bb4db689e8\",\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:44.246397Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.247702Z\",\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"d9a9ffd4-6b04-40ab-89d5-a7e73a218d3d\",\n",
      "    \"instrument_id\": \"ce1b543b-c30f-4f78-bd5b-1c71c292a826\",\n",
      "    \"default_storage_location_id\": \"74ec55b3-03ae-4a25-8e98-848a2334cf1d\",\n",
      "    \"cron_expression\": \"0 4 * * *\",\n",
      "    \"prefect_deployment_id\": \"97de6fc4-bc55-4380-9b8c-ce1becb5d087\",\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:44.281204Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.282386Z\",\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"b0b7ca9a-2124-4e1d-a0f0-6d1a864bf97c\",\n",
      "    \"instrument_id\": \"d9effe9b-e447-4edb-8b8d-e599a387b615\",\n",
      "    \"default_storage_location_id\": \"68909814-0d93-43ec-89d3-738f86ee3c26\",\n",
      "    \"cron_expression\": \"0 0 * * *\",\n",
      "    \"prefect_deployment_id\": \"d614cfb1-fc33-4b13-ac01-352a978a4cbd\",\n",
      "    \"enabled\": true,\n",
      "    \"created_at\": \"2026-03-01T18:50:44.312486Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.313519Z\",\n",
      "    \"deleted_at\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(\"/api/schedules\")\n",
    "schedules = resp.json()\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Hooks\n",
    "\n",
    "Expected: 3 hooks:\n",
    "\n",
    "- **Auto-assign file access on transfer** (`post_transfer`, `access_assignment`)\n",
    "- **NMR metadata enrichment** (`post_transfer`, `metadata_enrichment`, scoped to NMR instrument)\n",
    "- **File size filter — skip temp files** (`pre_transfer`, `file_filter`, excludes `*.tmp`, `*.lock`, `~*`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"ef27a4b4-9b51-4725-a91b-b1897b2f15f2\",\n",
      "    \"name\": \"Auto-assign file access on transfer\",\n",
      "    \"description\": \"Grants the instrument owner read access to every transferred file\",\n",
      "    \"trigger\": \"post_transfer\",\n",
      "    \"implementation\": \"builtin\",\n",
      "    \"builtin_name\": \"access_assignment\",\n",
      "    \"script_path\": null,\n",
      "    \"webhook_url\": null,\n",
      "    \"config\": null,\n",
      "    \"instrument_id\": null,\n",
      "    \"priority\": 0,\n",
      "    \"enabled\": true,\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"8787cc10-1a82-44c2-9cca-7ec48f3d8190\",\n",
      "    \"name\": \"NMR metadata enrichment\",\n",
      "    \"description\": \"Extracts pulse programme, solvent, and nucleus from Bruker acqus files\",\n",
      "    \"trigger\": \"post_transfer\",\n",
      "    \"implementation\": \"builtin\",\n",
      "    \"builtin_name\": \"metadata_enrichment\",\n",
      "    \"script_path\": null,\n",
      "    \"webhook_url\": null,\n",
      "    \"config\": null,\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"priority\": 10,\n",
      "    \"enabled\": true,\n",
      "    \"deleted_at\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"caa56d95-3503-4691-95d8-eee272f12a2f\",\n",
      "    \"name\": \"Skip zero-byte and temp files\",\n",
      "    \"description\": \"Drops zero-byte and .tmp files before transfer\",\n",
      "    \"trigger\": \"pre_transfer\",\n",
      "    \"implementation\": \"builtin\",\n",
      "    \"builtin_name\": \"file_filter\",\n",
      "    \"script_path\": null,\n",
      "    \"webhook_url\": null,\n",
      "    \"config\": {\n",
      "      \"min_size_bytes\": 1,\n",
      "      \"exclude_patterns\": [\n",
      "        \"*.tmp\",\n",
      "        \"*.lock\",\n",
      "        \"~*\"\n",
      "      ]\n",
      "    },\n",
      "    \"instrument_id\": null,\n",
      "    \"priority\": 0,\n",
      "    \"enabled\": true,\n",
      "    \"deleted_at\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(\"/api/hooks\")\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMR instrument: Bruker AVANCE III 600 MHz NMR\n",
      "Schedule ID: 8a67bb69-a550-4d1a-b1f1-d51f38f25b10\n",
      "Prefect deployment ID: 31f59cc3-c9cc-459e-a437-73bb4db689e8\n"
     ]
    }
   ],
   "source": [
    "# Save the NMR schedule ID (first schedule) for use in later steps\n",
    "instruments = client.get(\"/api/instruments\").json()\n",
    "nmr = next(i for i in instruments if \"NMR\" in i[\"name\"])\n",
    "NMR_SCHEDULE = next(\n",
    "    s for s in schedules if s[\"instrument_id\"] == nmr[\"id\"]\n",
    ")\n",
    "SCHEDULE_ID = NMR_SCHEDULE[\"id\"]\n",
    "print(f\"NMR instrument: {nmr['name']}\")\n",
    "print(f\"Schedule ID: {SCHEDULE_ID}\")\n",
    "print(f\"Prefect deployment ID: {NMR_SCHEDULE.get('prefect_deployment_id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Prefect Integration\n",
    "\n",
    "### 4a. Check Prefect UI\n",
    "\n",
    "Open **https://streamweave.local/** in a browser, login in the default admin (this saves a cookie so you can access the Prefect interface), and then view the Prefect dashboard by clicking `Admin -> Prefect Dashboard`.\n",
    "You should see:\n",
    "\n",
    "- **Deployments** tab: 3 deployments named `harvest-{instrument_name}`\n",
    "- **Work Pools** tab: a pool named **streamweave-worker-pool** with an active worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Trigger a manual harvest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"flow_run_id\": \"9d429f74-2a5a-478f-a7b4-787fbb3d8194\",\n",
      "  \"schedule_id\": \"8a67bb69-a550-4d1a-b1f1-d51f38f25b10\"\n",
      "}\n",
      "\n",
      "Make sure to login as an admin at https://streamweave.local, then\n",
      "View the run at https://streamweave.local/prefect/runs/flow-run/9d429f74-2a5a-478f-a7b4-787fbb3d8194\n",
      "Waiting for flow run 9d429f74-2a5a-478f-a7b4-787fbb3d8194 to complete...\n",
      "  State: SCHEDULED (attempt 1/120)\n",
      "  State: SCHEDULED (attempt 2/120)\n",
      "  State: SCHEDULED (attempt 3/120)\n",
      "  State: PENDING (attempt 4/120)\n",
      "  State: PENDING (attempt 5/120)\n",
      "  State: PENDING (attempt 6/120)\n",
      "  State: PENDING (attempt 7/120)\n",
      "  State: PENDING (attempt 8/120)\n",
      "  State: PENDING (attempt 9/120)\n",
      "  State: PENDING (attempt 10/120)\n",
      "  State: PENDING (attempt 11/120)\n",
      "  State: PENDING (attempt 12/120)\n",
      "  State: PENDING (attempt 13/120)\n",
      "  State: PENDING (attempt 14/120)\n",
      "  State: PENDING (attempt 15/120)\n",
      "  State: PENDING (attempt 16/120)\n",
      "  State: PENDING (attempt 17/120)\n",
      "  State: PENDING (attempt 18/120)\n",
      "  State: PENDING (attempt 19/120)\n",
      "  State: PENDING (attempt 20/120)\n",
      "Flow run finished with state: COMPLETED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETED'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = client.post(f\"/api/schedules/{SCHEDULE_ID}/trigger\", headers=AUTH)\n",
    "pp(resp)\n",
    "FLOW_RUN_ID = resp.json().get(\"flow_run_id\")\n",
    "print(f\"\\nMake sure to login as an admin at https://streamweave.local, then\\nView the run at https://streamweave.local/prefect/runs/flow-run/{FLOW_RUN_ID}\")\n",
    "wait_for_flow_run(FLOW_RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected response:\n",
    "```json\n",
    "{\n",
    "  \"flow_run_id\": \"<uuid>\",\n",
    "  \"schedule_id\": \"<uuid>\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Monitor in Prefect UI\n",
    "\n",
    "Go to **https://streamweave.local/prefect/flow-runs** (or the link above) and watch the triggered flow run. It will:\n",
    "\n",
    "1. Run `discover_files_task` — discovers files on the NMR's Samba share (10, if this is the first time it has run)\n",
    "2. Run `transfer_single_file_task` for each new file — transfers via rclone\n",
    "\n",
    "The run details in the Prefect interface show the ten original files being found, and transferred:\n",
    "\n",
    "<img src=\"_static/prefect_flowrun_logs.png\" width=\"80%\" style=\"margin-left: 3em\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Harvest Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. File discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should have found 10 example files from the NMR instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 10 files\n",
      "[\n",
      "  {\n",
      "    \"id\": \"bce71eae-cb34-4334-a758-a0f8b209465f\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4rop5mzxczjhbpc2sbzzb5zqkey\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260201_alanine_13C/pdata/1/1r\",\n",
      "    \"filename\": \"1r\",\n",
      "    \"size_bytes\": 8192,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.907000Z\",\n",
      "    \"xxhash\": \"f90b1bb50d3a727b\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:03:52.227456Z\",\n",
      "    \"metadata_\": {},\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"ef6a5662-53ab-4c4e-aa63-42766ca4abc7\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4wjt5tm7fvnauvkb7pqjnwsenjq\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260201_alanine_13C/fid\",\n",
      "    \"filename\": \"fid\",\n",
      "    \"size_bytes\": 16384,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.909000Z\",\n",
      "    \"xxhash\": \"b9ae9fcc0155a1c7\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:03:52.181062Z\",\n",
      "    \"metadata_\": {},\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"0d493f8c-39da-4860-b18d-80851d238134\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4yzwym4e62nhcbg3cswrvnfiixi\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260201_alanine_13C/acqus\",\n",
      "    \"filename\": \"acqus\",\n",
      "    \"size_bytes\": 470,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.911000Z\",\n",
      "    \"xxhash\": \"cea07227a98f977f\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:03:52.132839Z\",\n",
      "    \"metadata_\": {},\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  \"...\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(\"/api/files\", headers=AUTH)\n",
    "print(f\"\\nFound {len(resp.json())} files\")\n",
    "pp(resp, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file you should see:\n",
    "- `persistent_id` starting with `ark:/99999/fk4...` (unique ARK identifier)\n",
    "- `instrument_id` matching the harvested instrument\n",
    "- `source_path` matching the file's path on the instrument\n",
    "- `filename` — the file name\n",
    "- `xxhash` — checksum computed after transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. File transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, there should be 10 transfer actions for each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 transfers\n",
      "[\n",
      "  {\n",
      "    \"id\": \"6325c13b-39d5-4d5e-8d9d-92848ea1c2aa\",\n",
      "    \"file_id\": \"e7f9711c-be40-4fc3-8d16-f3d57ceeff95\",\n",
      "    \"storage_location_id\": \"74ec55b3-03ae-4a25-8e98-848a2334cf1d\",\n",
      "    \"destination_path\": \"/storage/posix-archive/Bruker AVANCE III 600 MHz NMR/20260210_ethanol_COSY/acqus\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"status\": \"completed\",\n",
      "    \"bytes_transferred\": 485,\n",
      "    \"source_checksum\": null,\n",
      "    \"dest_checksum\": \"13a9a75aebeedaa8\",\n",
      "    \"checksum_verified\": false,\n",
      "    \"started_at\": \"2026-03-01T19:03:51.807025Z\",\n",
      "    \"completed_at\": \"2026-03-01T19:03:51.852758Z\",\n",
      "    \"error_message\": null,\n",
      "    \"prefect_flow_run_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"3b7a9e5b-ec53-4708-b468-347afb92876b\",\n",
      "    \"file_id\": \"d2f98906-ce51-47b8-8381-ce7dbdbe3dcc\",\n",
      "    \"storage_location_id\": \"74ec55b3-03ae-4a25-8e98-848a2334cf1d\",\n",
      "    \"destination_path\": \"/storage/posix-archive/Bruker AVANCE III 600 MHz NMR/20260210_ethanol_COSY/fid\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"status\": \"completed\",\n",
      "    \"bytes_transferred\": 32768,\n",
      "    \"source_checksum\": null,\n",
      "    \"dest_checksum\": \"5cf4a5b010130869\",\n",
      "    \"checksum_verified\": false,\n",
      "    \"started_at\": \"2026-03-01T19:03:51.862462Z\",\n",
      "    \"completed_at\": \"2026-03-01T19:03:51.901336Z\",\n",
      "    \"error_message\": null,\n",
      "    \"prefect_flow_run_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"c55deca8-da15-4ff1-b37f-fc2f84ef6628\",\n",
      "    \"file_id\": \"64ea643b-4212-4f3b-97e3-fc0ad550109e\",\n",
      "    \"storage_location_id\": \"74ec55b3-03ae-4a25-8e98-848a2334cf1d\",\n",
      "    \"destination_path\": \"/storage/posix-archive/Bruker AVANCE III 600 MHz NMR/20260210_ethanol_COSY/pdata/1/1r\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"status\": \"completed\",\n",
      "    \"bytes_transferred\": 8192,\n",
      "    \"source_checksum\": null,\n",
      "    \"dest_checksum\": \"09bb4e0e5d27d746\",\n",
      "    \"checksum_verified\": false,\n",
      "    \"started_at\": \"2026-03-01T19:03:51.910097Z\",\n",
      "    \"completed_at\": \"2026-03-01T19:03:51.947217Z\",\n",
      "    \"error_message\": null,\n",
      "    \"prefect_flow_run_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"677d3e99-bf1a-4b1a-a56e-e8783bb2eab6\",\n",
      "    \"file_id\": \"1e37b56d-40df-4632-9405-02341ee47313\",\n",
      "    \"storage_location_id\": \"74ec55b3-03ae-4a25-8e98-848a2334cf1d\",\n",
      "    \"destination_path\": \"/storage/posix-archive/Bruker AVANCE III 600 MHz NMR/20260115_glucose_1H/acqus\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"status\": \"completed\",\n",
      "    \"bytes_transferred\": 998,\n",
      "    \"source_checksum\": null,\n",
      "    \"dest_checksum\": \"93fa612f0dfeb7e8\",\n",
      "    \"checksum_verified\": false,\n",
      "    \"started_at\": \"2026-03-01T19:03:51.954812Z\",\n",
      "    \"completed_at\": \"2026-03-01T19:03:51.992123Z\",\n",
      "    \"error_message\": null,\n",
      "    \"prefect_flow_run_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"770cb8e7-3344-40ff-b1a8-d6c13f8efc20\",\n",
      "    \"file_id\": \"a195cc61-8d44-414a-8bb6-72be2b61c96a\",\n",
      "    \"storage_location_id\": \"74ec55b3-03ae-4a25-8e98-848a2334cf1d\",\n",
      "    \"destination_path\": \"/storage/posix-archive/Bruker AVANCE III 600 MHz NMR/20260115_glucose_1H/fid\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"status\": \"completed\",\n",
      "    \"bytes_transferred\": 8192,\n",
      "    \"source_checksum\": null,\n",
      "    \"dest_checksum\": \"8852c19b353053af\",\n",
      "    \"checksum_verified\": false,\n",
      "    \"started_at\": \"2026-03-01T19:03:51.999780Z\",\n",
      "    \"completed_at\": \"2026-03-01T19:03:52.035077Z\",\n",
      "    \"error_message\": null,\n",
      "    \"prefect_flow_run_id\": null\n",
      "  },\n",
      "  \"...\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(\"/api/transfers\", headers=AUTH)\n",
    "print(f\"Found {len(resp.json())} transfers\")\n",
    "pp(resp, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each transfer should have:\n",
    "- `status`: `\"completed\"` or `\"skipped\"`\n",
    "- `dest_checksum` — xxhash of the transferred file\n",
    "- `destination_path` — where the file was written under `/storage/`\n",
    "- `bytes_transferred` — file size\n",
    "- `started_at` and `completed_at` timestamps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c. Check files on disk (in the source directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/nmr/20260115_glucose_1H/acqus\n",
      "/data/nmr/20260115_glucose_1H/fid\n",
      "/data/nmr/20260115_glucose_1H/pdata/1/1r\n",
      "/data/nmr/20260115_glucose_1H/pdata/1/procs\n",
      "/data/nmr/20260201_alanine_13C/acqus\n",
      "/data/nmr/20260201_alanine_13C/fid\n",
      "/data/nmr/20260201_alanine_13C/pdata/1/1r\n",
      "/data/nmr/20260210_ethanol_COSY/acqus\n",
      "/data/nmr/20260210_ethanol_COSY/fid\n",
      "/data/nmr/20260210_ethanol_COSY/pdata/1/1r\n"
     ]
    }
   ],
   "source": [
    "_ = run(f\"docker compose {DEV_COMPOSE} exec samba-instruments find /data/nmr -type f | sort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5d. Check files on disk (in the storage directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/posix-archive/\n",
      "└── Bruker AVANCE III 600 MHz NMR\n",
      "    ├── 20260115_glucose_1H\n",
      "    │   ├── acqus\n",
      "    │   ├── fid\n",
      "    │   └── pdata\n",
      "    │       └── 1\n",
      "    │           ├── 1r\n",
      "    │           └── procs\n",
      "    ├── 20260201_alanine_13C\n",
      "    │   ├── acqus\n",
      "    │   ├── fid\n",
      "    │   └── pdata\n",
      "    │       └── 1\n",
      "    │           └── 1r\n",
      "    └── 20260210_ethanol_COSY\n",
      "        ├── acqus\n",
      "        ├── fid\n",
      "        └── pdata\n",
      "            └── 1\n",
      "                └── 1r\n",
      "\n",
      "11 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "_ = run(f\"docker compose {DEV_COMPOSE} exec api tree /storage/posix-archive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Pre-Transfer Hook (File Filter)\n",
    "\n",
    "The **file size filter** hook skips zero-byte files and files matching\n",
    "`*.tmp`, `*.lock`, `~*` patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Add a temp and empty file to the NMR instrument share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in NMR share:\n",
      "-------------------\n",
      "./20260115_glucose_1H/acqus\n",
      "./20260115_glucose_1H/fid\n",
      "./20260115_glucose_1H/pdata/1/1r\n",
      "./20260115_glucose_1H/pdata/1/procs\n",
      "./20260201_alanine_13C/acqus\n",
      "./20260201_alanine_13C/fid\n",
      "./20260201_alanine_13C/pdata/1/1r\n",
      "./20260210_ethanol_COSY/acqus\n",
      "./20260210_ethanol_COSY/fid\n",
      "./20260210_ethanol_COSY/pdata/1/1r\n",
      "./empty.txt\n",
      "./scratch.tmp\n"
     ]
    }
   ],
   "source": [
    "# Write a .tmp file and empty .txt file into the samba-instruments volume\n",
    "# via docker exec - this simulates two new files being created by the instrument\n",
    "_ = run(f'docker compose {DEV_COMPOSE} exec samba-instruments sh -c '\n",
    "  '\"echo temp data > /data/nmr/scratch.tmp && truncate -s 0 /data/nmr/empty.txt\"')\n",
    "print(\"Files in NMR share:\\n-------------------\")\n",
    "_ = run(f'docker compose {DEV_COMPOSE} exec samba-instruments sh -c '\n",
    "      '\"cd /data/nmr && find . -type f | sort\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Trigger another harvest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"flow_run_id\": \"184c1bef-e57a-451a-adee-851fb483a6f6\",\n",
      "  \"schedule_id\": \"8a67bb69-a550-4d1a-b1f1-d51f38f25b10\"\n",
      "}\n",
      "\n",
      "View the run at https://streamweave.local/prefect/runs/flow-run/184c1bef-e57a-451a-adee-851fb483a6f6\n",
      "Waiting for flow run 184c1bef-e57a-451a-adee-851fb483a6f6 to complete...\n",
      "  State: SCHEDULED (attempt 1/120)\n",
      "  State: SCHEDULED (attempt 2/120)\n",
      "  State: SCHEDULED (attempt 3/120)\n",
      "  State: SCHEDULED (attempt 4/120)\n",
      "  State: SCHEDULED (attempt 5/120)\n",
      "  State: SCHEDULED (attempt 6/120)\n",
      "  State: SCHEDULED (attempt 7/120)\n",
      "  State: SCHEDULED (attempt 8/120)\n",
      "  State: SCHEDULED (attempt 9/120)\n",
      "  State: SCHEDULED (attempt 10/120)\n",
      "  State: SCHEDULED (attempt 11/120)\n",
      "  State: PENDING (attempt 12/120)\n",
      "  State: PENDING (attempt 13/120)\n",
      "  State: PENDING (attempt 14/120)\n",
      "  State: PENDING (attempt 15/120)\n",
      "  State: PENDING (attempt 16/120)\n",
      "  State: PENDING (attempt 17/120)\n",
      "  State: PENDING (attempt 18/120)\n",
      "  State: PENDING (attempt 19/120)\n",
      "  State: PENDING (attempt 20/120)\n",
      "  State: PENDING (attempt 21/120)\n",
      "  State: PENDING (attempt 22/120)\n",
      "  State: PENDING (attempt 23/120)\n",
      "  State: PENDING (attempt 24/120)\n",
      "  State: PENDING (attempt 25/120)\n",
      "Flow run finished with state: COMPLETED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETED'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = client.post(f\"/api/schedules/{SCHEDULE_ID}/trigger\")\n",
    "IGNORE_FLOW_RUN_ID = resp.json().get(\"flow_run_id\")\n",
    "pp(resp)\n",
    "print(f\"\\nView the run at https://streamweave.local/prefect/runs/flow-run/{IGNORE_FLOW_RUN_ID}\")\n",
    "wait_for_flow_run(IGNORE_FLOW_RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run details in the Prefect interface show the two new files being found, and skipped:\n",
    "\n",
    "<img src=\"_static/prefect_flowrun_logs_skip_tmp.png\" width=\"80%\" style=\"margin-left: 3em\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Verify the .tmp file was skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StreamWeave has a demonstration pre-transfer hook that ignores certain file patterns. These can be configured easily on a per-instrument basis. The following example will show that the `scratch.tmp` file is discovered in the file finding flow, but is not transferred due to the pre-transfer hook blocking it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:\n",
      "------\n",
      "[\n",
      "  {\n",
      "    \"id\": \"b8717eb9-d07e-4b20-8fb3-a92b393f7014\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4t4evdj3gwvgmxdoggpvubfywdy\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"scratch.tmp\",\n",
      "    \"filename\": \"scratch.tmp\",\n",
      "    \"size_bytes\": 10,\n",
      "    \"source_mtime\": \"2026-03-01T19:04:17.434000Z\",\n",
      "    \"xxhash\": null,\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:04:46.802470Z\",\n",
      "    \"metadata_\": {},\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"a6ac9d3b-6f52-49fd-b248-bc01f0067e1f\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4iuqtofcervhodatcyycx54ps3q\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"empty.txt\",\n",
      "    \"filename\": \"empty.txt\",\n",
      "    \"size_bytes\": 0,\n",
      "    \"source_mtime\": \"2026-03-01T19:04:17.434000Z\",\n",
      "    \"xxhash\": null,\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:04:46.788376Z\",\n",
      "    \"metadata_\": {},\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"bce71eae-cb34-4334-a758-a0f8b209465f\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4rop5mzxczjhbpc2sbzzb5zqkey\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260201_alanine_13C/pdata/1/1r\",\n",
      "    \"filename\": \"1r\",\n",
      "    \"size_bytes\": 8192,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.907000Z\",\n",
      "    \"xxhash\": \"f90b1bb50d3a727b\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:03:52.227456Z\",\n",
      "    \"metadata_\": {},\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"ef6a5662-53ab-4c4e-aa63-42766ca4abc7\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4wjt5tm7fvnauvkb7pqjnwsenjq\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260201_alanine_13C/fid\",\n",
      "    \"filename\": \"fid\",\n",
      "    \"size_bytes\": 16384,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.909000Z\",\n",
      "    \"xxhash\": \"b9ae9fcc0155a1c7\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:03:52.181062Z\",\n",
      "    \"metadata_\": {},\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  \"...\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"Files:\\n------\")\n",
    "resp = client.get(\"/api/files\")\n",
    "pp(resp, n=4)\n",
    "# nmr/scratch.tmp and nmr/empty.txt will be in the file list printed out at this step,\n",
    "# since they were discovered, but we will confirm they were not transferred in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS: scratch.tmp was correctly filtered by the pre-transfer hook (transfer skipped)\n"
     ]
    }
   ],
   "source": [
    "# firmly assert that the scratch.tmp file was found\n",
    "files = resp.json()\n",
    "scratch = next((f for f in files if f[\"filename\"] == \"scratch.tmp\"), None)\n",
    "assert scratch is not None, \"FAIL: scratch.tmp file record not found\"\n",
    "\n",
    "# firmly assert that the scratch.tmp file was not transferred\n",
    "transfers = client.get(f\"/api/transfers?file_id={scratch['id']}\").json()\n",
    "assert all(t[\"status\"] == \"skipped\" for t in transfers), \"FAIL: scratch.tmp should only have skipped transfers\"\n",
    "print(\"PASS: scratch.tmp was correctly filtered by the pre-transfer hook (transfer skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Post-Transfer Hook (Metadata Enrichment)\n",
    "\n",
    "StreamWeave supports post-transfer hooks that can extract scientific metadata\n",
    "from either files or the file paths, which is a common pattern for laboratories to encode metadata.\n",
    "\n",
    "This example will configure a hook with regex rules that extract the **date**, **compound**, and **nucleus**\n",
    "from Bruker NMR folder names like `20260115_glucose_1H/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Update the hook with extraction rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"8787cc10-1a82-44c2-9cca-7ec48f3d8190\",\n",
      "  \"name\": \"NMR metadata enrichment\",\n",
      "  \"description\": \"Extracts pulse programme, solvent, and nucleus from Bruker acqus files\",\n",
      "  \"trigger\": \"post_transfer\",\n",
      "  \"implementation\": \"builtin\",\n",
      "  \"builtin_name\": \"metadata_enrichment\",\n",
      "  \"script_path\": null,\n",
      "  \"webhook_url\": null,\n",
      "  \"config\": null,\n",
      "  \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "  \"priority\": 10,\n",
      "  \"enabled\": true,\n",
      "  \"deleted_at\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Find the NMR metadata enrichment hook\n",
    "hooks = client.get(\"/api/hooks\").json()\n",
    "nmr_hook = next(h for h in hooks if \"NMR\" in h[\"name\"])\n",
    "pp_dict(nmr_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated hook: 200\n",
      "{\n",
      "  \"id\": \"8787cc10-1a82-44c2-9cca-7ec48f3d8190\",\n",
      "  \"name\": \"NMR metadata enrichment\",\n",
      "  \"description\": \"Extracts pulse programme, solvent, and nucleus from Bruker acqus files\",\n",
      "  \"trigger\": \"post_transfer\",\n",
      "  \"implementation\": \"builtin\",\n",
      "  \"builtin_name\": \"metadata_enrichment\",\n",
      "  \"script_path\": null,\n",
      "  \"webhook_url\": null,\n",
      "  \"config\": {\n",
      "    \"rules\": [\n",
      "      {\n",
      "        \"source\": \"path\",\n",
      "        \"pattern\": \"^(?P<date>\\\\d{8})_(?P<compound>[^_/]+)_(?P<nucleus>[^/]+)/\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "  \"priority\": 10,\n",
      "  \"enabled\": true,\n",
      "  \"deleted_at\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Update it with regex rules to extract experiment metadata from the path\n",
    "resp = client.patch(f\"/api/hooks/{nmr_hook['id']}\", json={\n",
    "    \"config\": {\n",
    "        \"rules\": [\n",
    "            {\n",
    "                \"source\": \"path\",\n",
    "                \"pattern\": r\"^(?P<date>\\d{8})_(?P<compound>[^_/]+)_(?P<nucleus>[^/]+)/\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "})\n",
    "print(f\"Updated hook: {resp.status_code}\")\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. Clear transferred files and re-harvest\n",
    "\n",
    "Delete all file records and transferred files so the harvest runs fresh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE 12\n",
      "DELETE 12\n",
      "\n",
      "View the run at https://streamweave.local/prefect/runs/flow-run/b431a2d3-e585-4c63-92ef-43f4ee897943\n",
      "{\n",
      "  \"flow_run_id\": \"b431a2d3-e585-4c63-92ef-43f4ee897943\",\n",
      "  \"schedule_id\": \"8a67bb69-a550-4d1a-b1f1-d51f38f25b10\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "_ = run(f\"docker compose {DEV_COMPOSE} exec worker rm -rf /storage/posix-archive/*\")\n",
    "_ = run(f'docker compose {DEV_COMPOSE} exec postgres psql -U streamweave -c \"DELETE FROM file_transfers; DELETE FROM file_records;\"')\n",
    "\n",
    "resp = client.post(f\"/api/schedules/{SCHEDULE_ID}/trigger\", headers=AUTH)\n",
    "METADATA_FLOW_RUN_ID = resp.json().get(\"flow_run_id\")\n",
    "print(f\"\\nView the run at https://streamweave.local/prefect/runs/flow-run/{METADATA_FLOW_RUN_ID}\")\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run details in the Prefect interface show the metadata being extracted from the paths and\n",
    "added to the file records:\n",
    "\n",
    "<img src=\"_static/prefect_flowrun_logs_metadata_enrichment.png\" width=\"80%\" style=\"margin-left: 3em\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"71a84edd-4a27-4481-a6c4-43322ea5c150\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4r3unsl7tubcqldkbfcpeknetoq\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260201_alanine_13C/pdata/1/1r\",\n",
      "    \"filename\": \"1r\",\n",
      "    \"size_bytes\": 8192,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.907000Z\",\n",
      "    \"xxhash\": \"f90b1bb50d3a727b\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:05:52.296240Z\",\n",
      "    \"metadata_\": {\n",
      "      \"date\": \"20260201\",\n",
      "      \"compound\": \"alanine\",\n",
      "      \"nucleus\": \"13C\"\n",
      "    },\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"8f188084-22b2-4cf3-96db-beea2d76f1d3\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4arrbenrghnanllfmppq3ke7asq\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260201_alanine_13C/fid\",\n",
      "    \"filename\": \"fid\",\n",
      "    \"size_bytes\": 16384,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.909000Z\",\n",
      "    \"xxhash\": \"b9ae9fcc0155a1c7\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:05:52.250062Z\",\n",
      "    \"metadata_\": {\n",
      "      \"date\": \"20260201\",\n",
      "      \"compound\": \"alanine\",\n",
      "      \"nucleus\": \"13C\"\n",
      "    },\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"c6d232c8-3a16-4a7d-a64d-4dc059a0ba06\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4xsmiwjo5qvdfrikx5si64e6uce\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260201_alanine_13C/acqus\",\n",
      "    \"filename\": \"acqus\",\n",
      "    \"size_bytes\": 470,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.911000Z\",\n",
      "    \"xxhash\": \"cea07227a98f977f\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:05:52.207146Z\",\n",
      "    \"metadata_\": {\n",
      "      \"date\": \"20260201\",\n",
      "      \"compound\": \"alanine\",\n",
      "      \"nucleus\": \"13C\"\n",
      "    },\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"105c155e-4c0d-4671-9b82-3448de45f26b\",\n",
      "    \"persistent_id\": \"ark:/99999/fk4o5dhk4sh7nd67eagd7fh4l7ke4\",\n",
      "    \"persistent_id_type\": \"ark\",\n",
      "    \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "    \"source_path\": \"20260115_glucose_1H/pdata/1/procs\",\n",
      "    \"filename\": \"procs\",\n",
      "    \"size_bytes\": 403,\n",
      "    \"source_mtime\": \"2026-03-01T18:50:25.917000Z\",\n",
      "    \"xxhash\": \"2416b2a237343510\",\n",
      "    \"sha256\": null,\n",
      "    \"first_discovered_at\": \"2026-03-01T19:05:52.162174Z\",\n",
      "    \"metadata_\": {\n",
      "      \"date\": \"20260115\",\n",
      "      \"compound\": \"glucose\",\n",
      "      \"nucleus\": \"1H\"\n",
      "    },\n",
      "    \"owner_id\": null\n",
      "  },\n",
      "  \"...\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Fetching file records from the API displays extracted metadata under the \"metadata_\" key:\n",
    "resp = client.get(\"/api/files\")\n",
    "pp(resp, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. User-Scoped Access Control Demo\n",
    "\n",
    "Files are private by default. Access is granted explicitly to users, groups, or projects via the `FileAccessGrant` system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. Get regular user token and user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: b1662f8b-0371-4027-ab87-a466565f2859\n"
     ]
    }
   ],
   "source": [
    "resp = client.post(\"/auth/jwt/login\", data={\"username\": \"chemist@example.com\", \"password\": \"devpass123!\"})\n",
    "USER_TOKEN = resp.json()[\"access_token\"]\n",
    "USER_AUTH = {\"Authorization\": f\"Bearer {USER_TOKEN}\"}\n",
    "\n",
    "resp = client.get(\"/users/me\", headers=USER_AUTH)\n",
    "USER_ID = resp.json()[\"id\"]\n",
    "print(f\"User ID: {USER_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Verify user sees no files (no access granted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: []\n",
      "Transfers: []\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(\"/api/files\", headers=USER_AUTH)\n",
    "print(\"Files:\", resp.json())\n",
    "# Expected: []\n",
    "\n",
    "resp = client.get(\"/api/transfers\", headers=USER_AUTH)\n",
    "print(\"Transfers:\", resp.json())\n",
    "# Expected: []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Grant direct user access to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: 71a84edd-4a27-4481-a6c4-43322ea5c150\n",
      "{\n",
      "  \"id\": \"302dd350-ebfc-40aa-b881-5aa2d6c11e24\",\n",
      "  \"file_id\": \"71a84edd-4a27-4481-a6c4-43322ea5c150\",\n",
      "  \"grantee_type\": \"user\",\n",
      "  \"grantee_id\": \"b1662f8b-0371-4027-ab87-a466565f2859\",\n",
      "  \"granted_at\": \"2026-03-01T19:06:00.164792Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pick a file to grant access to\n",
    "FILE_ID = client.get(\"/api/files\", headers=AUTH).json()[0][\"id\"]\n",
    "print(f\"File ID: {FILE_ID}\")\n",
    "\n",
    "# Grant the user access (admin-only endpoint)\n",
    "resp = client.post(f\"/api/files/{FILE_ID}/access\", headers=AUTH, json={\n",
    "    \"grantee_type\": \"user\",\n",
    "    \"grantee_id\": USER_ID,\n",
    "})\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected response:\n",
    "```json\n",
    "{\n",
    "  \"id\": \"<grant-uuid>\",\n",
    "  \"file_id\": \"<file-uuid>\",\n",
    "  \"grantee_type\": \"user\",\n",
    "  \"grantee_id\": \"<user-uuid>\",\n",
    "  \"granted_at\": \"2026-02-23T...\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8d. Verify user now sees the granted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files visible to user: 1\n",
      "{\n",
      "  \"id\": \"71a84edd-4a27-4481-a6c4-43322ea5c150\",\n",
      "  \"persistent_id\": \"ark:/99999/fk4r3unsl7tubcqldkbfcpeknetoq\",\n",
      "  \"persistent_id_type\": \"ark\",\n",
      "  \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "  \"source_path\": \"20260201_alanine_13C/pdata/1/1r\",\n",
      "  \"filename\": \"1r\",\n",
      "  \"size_bytes\": 8192,\n",
      "  \"source_mtime\": \"2026-03-01T18:50:25.907000Z\",\n",
      "  \"xxhash\": \"f90b1bb50d3a727b\",\n",
      "  \"sha256\": null,\n",
      "  \"first_discovered_at\": \"2026-03-01T19:05:52.296240Z\",\n",
      "  \"metadata_\": {\n",
      "    \"date\": \"20260201\",\n",
      "    \"compound\": \"alanine\",\n",
      "    \"nucleus\": \"13C\"\n",
      "  },\n",
      "  \"owner_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(\"/api/files\", headers=USER_AUTH)\n",
    "print(f\"Files visible to user: {len(resp.json())}\")\n",
    "# Expected: exactly 1 file\n",
    "\n",
    "resp = client.get(f\"/api/files/{FILE_ID}\", headers=USER_AUTH)\n",
    "pp(resp)\n",
    "# Expected: 200 with full file details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8e. Verify 404 for files without access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"detail\": \"File not found\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "OTHER_FILE = client.get(\"/api/files\", headers=AUTH).json()[1][\"id\"]\n",
    "\n",
    "resp = client.get(f\"/api/files/{OTHER_FILE}\", headers=USER_AUTH)\n",
    "pp(resp)\n",
    "# Expected: {\"detail\": \"File not found\"} (404, not 403 — avoids leaking existence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8f. List and revoke a grant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"302dd350-ebfc-40aa-b881-5aa2d6c11e24\",\n",
      "    \"file_id\": \"71a84edd-4a27-4481-a6c4-43322ea5c150\",\n",
      "    \"grantee_type\": \"user\",\n",
      "    \"grantee_id\": \"b1662f8b-0371-4027-ab87-a466565f2859\",\n",
      "    \"granted_at\": \"2026-03-01T19:06:00.164792Z\"\n",
      "  }\n",
      "]\n",
      "Delete status: 204\n",
      "{\n",
      "  \"detail\": \"File not found\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# List grants for the file (admin only)\n",
    "resp = client.get(f\"/api/files/{FILE_ID}/access\", headers=AUTH)\n",
    "pp(resp)\n",
    "\n",
    "# Revoke the grant\n",
    "GRANT_ID = resp.json()[0][\"id\"]\n",
    "resp = client.delete(f\"/api/files/{FILE_ID}/access/{GRANT_ID}\", headers=AUTH)\n",
    "print(f\"Delete status: {resp.status_code}\")\n",
    "# Expected: 204\n",
    "\n",
    "# Verify user can no longer see the file\n",
    "resp = client.get(f\"/api/files/{FILE_ID}\", headers=USER_AUTH)\n",
    "pp(resp)\n",
    "# Expected: {\"detail\": \"File not found\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Group-Based Access Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File access can also be granted via group memberships, which are collections of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9a. Get groups for the example chemistry user and save the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "    \"name\": \"Chemistry & Chemical Biology\",\n",
      "    \"description\": \"Organic and inorganic chemistry researchers using NMR and HPLC\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.501381Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.501381Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"1c740a28-a95f-4b6f-9593-b657f1afcf0f\",\n",
      "    \"name\": \"Analytical Core\",\n",
      "    \"description\": \"Cross-departmental analytical instrumentation users\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.526027Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.526027Z\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Get the groups that chemist@example.com belongs to\n",
    "resp = client.get(f\"/api/admin/users/{USER_ID}/groups\")\n",
    "GROUP_ID = resp.json()[0][\"id\"]\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP 204: \n",
      "{\n",
      "  \"group_id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "  \"user_id\": \"b1662f8b-0371-4027-ab87-a466565f2859\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Remove the user from the group (just to demo the capability)\n",
    "resp = client.delete(f\"/api/groups/{GROUP_ID}/members/{USER_ID}\")\n",
    "pp(resp)\n",
    "\n",
    "# Add the user back to the group\n",
    "resp = client.post(f\"/api/groups/{GROUP_ID}/members\", json={\"user_id\": USER_ID})\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10B-b. Grant the group access to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"7da55044-184c-47c6-b84b-b694909584be\",\n",
      "  \"file_id\": \"71a84edd-4a27-4481-a6c4-43322ea5c150\",\n",
      "  \"grantee_type\": \"group\",\n",
      "  \"grantee_id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "  \"granted_at\": \"2026-03-01T19:23:45.108842Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp = client.post(f\"/api/files/{FILE_ID}/access\", json={\n",
    "    \"grantee_type\": \"group\",\n",
    "    \"grantee_id\": GROUP_ID,\n",
    "})\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10B-c. Verify user sees the file via group membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"71a84edd-4a27-4481-a6c4-43322ea5c150\",\n",
      "  \"persistent_id\": \"ark:/99999/fk4r3unsl7tubcqldkbfcpeknetoq\",\n",
      "  \"persistent_id_type\": \"ark\",\n",
      "  \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "  \"source_path\": \"20260201_alanine_13C/pdata/1/1r\",\n",
      "  \"filename\": \"1r\",\n",
      "  \"size_bytes\": 8192,\n",
      "  \"source_mtime\": \"2026-03-01T18:50:25.907000Z\",\n",
      "  \"xxhash\": \"f90b1bb50d3a727b\",\n",
      "  \"sha256\": null,\n",
      "  \"first_discovered_at\": \"2026-03-01T19:05:52.296240Z\",\n",
      "  \"metadata_\": {\n",
      "    \"date\": \"20260201\",\n",
      "    \"compound\": \"alanine\",\n",
      "    \"nucleus\": \"13C\"\n",
      "  },\n",
      "  \"owner_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(f\"/api/files/{FILE_ID}\", headers=USER_AUTH)\n",
    "pp(resp)\n",
    "# Expected: 200 — user can see the file because they're in the granted group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10B-d. Groups CRUD (Create, Read, Update, Delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All groups ===\n",
      "[\n",
      "  {\n",
      "    \"id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "    \"name\": \"Chemistry & Chemical Biology\",\n",
      "    \"description\": \"Organic and inorganic chemistry researchers using NMR and HPLC\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.501381Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.501381Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"78bff4ea-e383-4952-b102-91b737a9d1df\",\n",
      "    \"name\": \"Proteomics Core\",\n",
      "    \"description\": \"Mass spectrometry and proteomics platform users\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.512817Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.512817Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"22cd5316-8f08-431b-9ba6-00a409225e4d\",\n",
      "    \"name\": \"EM Facility\",\n",
      "    \"description\": \"Electron microscopy facility operators and approved users\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.521002Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.521002Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"1c740a28-a95f-4b6f-9593-b657f1afcf0f\",\n",
      "    \"name\": \"Analytical Core\",\n",
      "    \"description\": \"Cross-departmental analytical instrumentation users\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.526027Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.526027Z\"\n",
      "  }\n",
      "]\n",
      "\n",
      "=== Group details ===\n",
      "{\n",
      "  \"id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "  \"name\": \"Chemistry & Chemical Biology\",\n",
      "  \"description\": \"Organic and inorganic chemistry researchers using NMR and HPLC\",\n",
      "  \"created_at\": \"2026-03-01T18:50:44.501381Z\",\n",
      "  \"updated_at\": \"2026-03-01T18:50:44.501381Z\"\n",
      "}\n",
      "\n",
      "=== Group members ===\n",
      "[\n",
      "  {\n",
      "    \"group_id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "    \"user_id\": \"2e9706c8-8bf8-44bd-9ad5-839b014b3e0e\"\n",
      "  },\n",
      "  {\n",
      "    \"group_id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "    \"user_id\": \"b1662f8b-0371-4027-ab87-a466565f2859\"\n",
      "  }\n",
      "]\n",
      "\n",
      "=== Update group ===\n",
      "{\n",
      "  \"id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "  \"name\": \"Chemistry & Chemical Biology\",\n",
      "  \"description\": \"Updated description\",\n",
      "  \"created_at\": \"2026-03-01T18:50:44.501381Z\",\n",
      "  \"updated_at\": \"2026-03-01T19:24:09.048290Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# List groups\n",
    "print(\"=== All groups ===\")\n",
    "pp(client.get(\"/api/groups\"))\n",
    "\n",
    "# Get group details\n",
    "print(\"\\n=== Group details ===\")\n",
    "pp(client.get(f\"/api/groups/{GROUP_ID}\"))\n",
    "\n",
    "# List group members\n",
    "print(\"\\n=== Group members ===\")\n",
    "pp(client.get(f\"/api/groups/{GROUP_ID}/members\"))\n",
    "\n",
    "# Update group\n",
    "print(\"\\n=== Update group ===\")\n",
    "pp(client.patch(f\"/api/groups/{GROUP_ID}\", json={\"description\": \"Updated description\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove member status: 204\n",
      "{\n",
      "  \"detail\": \"File not found\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Remove member\n",
    "resp = client.delete(f\"/api/groups/{GROUP_ID}/members/{USER_ID}\", headers=AUTH)\n",
    "print(f\"Remove member status: {resp.status_code}\")\n",
    "# Expected: 204\n",
    "\n",
    "# Verify user lost access (group membership removed)\n",
    "resp = client.get(f\"/api/files/{FILE_ID}\", headers=USER_AUTH)\n",
    "pp(resp)\n",
    "# Expected: {\"detail\": \"File not found\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10C. Project-Based File Access Demo\n",
    "\n",
    "Projects can contain both individual users and entire groups. When a file is granted to a project, all members (direct users + users in member groups) can see it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 10C-a. Create a project with user and group members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: 2e8af5f2-6032-4648-80bf-269f9ca7cf80\n",
      "{\n",
      "  \"id\": \"573df377-8f42-4a46-b492-8353dc8b79c0\",\n",
      "  \"project_id\": \"2e8af5f2-6032-4648-80bf-269f9ca7cf80\",\n",
      "  \"member_type\": \"group\",\n",
      "  \"member_id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Re-add user to the group (removed in previous step)\n",
    "client.post(f\"/api/groups/{GROUP_ID}/members\", json={\"user_id\": USER_ID})\n",
    "\n",
    "# Create a new project\n",
    "resp = client.post(\"/api/projects\", json={\n",
    "    \"name\": \"Microscopy Study 2026\",\n",
    "    \"description\": \"Main research project\",\n",
    "})\n",
    "PROJECT_ID = resp.json()[\"id\"]\n",
    "print(f\"Project ID: {PROJECT_ID}\")\n",
    "\n",
    "# Add the group as a project member\n",
    "resp = client.post(f\"/api/projects/{PROJECT_ID}/members\", json={\n",
    "    \"member_type\": \"group\",\n",
    "    \"member_id\": GROUP_ID,\n",
    "})\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10C-b. Grant the project access to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up 1 existing grants\n",
      "{\n",
      "  \"id\": \"36798532-2334-4099-82f2-cdc0dffd5b07\",\n",
      "  \"file_id\": \"71a84edd-4a27-4481-a6c4-43322ea5c150\",\n",
      "  \"grantee_type\": \"project\",\n",
      "  \"grantee_id\": \"2e8af5f2-6032-4648-80bf-269f9ca7cf80\",\n",
      "  \"granted_at\": \"2026-03-01T19:25:10.619618Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Clean up previous grants on the file\n",
    "grants = client.get(f\"/api/files/{FILE_ID}/access\").json()\n",
    "for g in grants:\n",
    "    client.delete(f\"/api/files/{FILE_ID}/access/{g['id']}\")\n",
    "print(f\"Cleaned up {len(grants)} existing grants\")\n",
    "\n",
    "# Grant project access\n",
    "resp = client.post(f\"/api/files/{FILE_ID}/access\", json={\n",
    "    \"grantee_type\": \"project\",\n",
    "    \"grantee_id\": PROJECT_ID,\n",
    "})\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10C-c. Verify user sees the file via project → group → user chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"71a84edd-4a27-4481-a6c4-43322ea5c150\",\n",
      "  \"persistent_id\": \"ark:/99999/fk4r3unsl7tubcqldkbfcpeknetoq\",\n",
      "  \"persistent_id_type\": \"ark\",\n",
      "  \"instrument_id\": \"e1b740df-3ef1-43d9-a47c-a2e210b4bd26\",\n",
      "  \"source_path\": \"20260201_alanine_13C/pdata/1/1r\",\n",
      "  \"filename\": \"1r\",\n",
      "  \"size_bytes\": 8192,\n",
      "  \"source_mtime\": \"2026-03-01T18:50:25.907000Z\",\n",
      "  \"xxhash\": \"f90b1bb50d3a727b\",\n",
      "  \"sha256\": null,\n",
      "  \"first_discovered_at\": \"2026-03-01T19:05:52.296240Z\",\n",
      "  \"metadata_\": {\n",
      "    \"date\": \"20260201\",\n",
      "    \"compound\": \"alanine\",\n",
      "    \"nucleus\": \"13C\"\n",
      "  },\n",
      "  \"owner_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(f\"/api/files/{FILE_ID}\", headers=USER_AUTH)\n",
    "pp(resp)\n",
    "# Expected: 200 — user can see the file because:\n",
    "#   user ∈ group → group ∈ project → project has file grant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10C-d. Test direct user membership in projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"c22064ae-cba3-4ff0-8645-e9a6a9e5c035\",\n",
      "  \"email\": \"postdoc@test.org\",\n",
      "  \"is_active\": true,\n",
      "  \"is_superuser\": false,\n",
      "  \"is_verified\": false,\n",
      "  \"role\": \"user\",\n",
      "  \"deleted_at\": null\n",
      "}\n",
      "Postdoc ID: c22064ae-cba3-4ff0-8645-e9a6a9e5c035\n",
      "{\n",
      "  \"id\": \"9a1ffc01-6eab-48dd-ae8f-8e6cd84f345c\",\n",
      "  \"project_id\": \"2e8af5f2-6032-4648-80bf-269f9ca7cf80\",\n",
      "  \"member_type\": \"user\",\n",
      "  \"member_id\": \"c22064ae-cba3-4ff0-8645-e9a6a9e5c035\"\n",
      "}\n",
      "\n",
      "Postdoc file access status: 200\n"
     ]
    }
   ],
   "source": [
    "# Create a second user\n",
    "resp = client.post(\"/auth/register\", json={\"email\": \"postdoc@test.org\", \"password\": \"testpassword123\"})\n",
    "pp(resp)\n",
    "\n",
    "resp = client.post(\"/auth/jwt/login\", data={\"username\": \"postdoc@test.org\", \"password\": \"testpassword123\"})\n",
    "POSTDOC_TOKEN = resp.json()[\"access_token\"]\n",
    "POSTDOC_AUTH = {\"Authorization\": f\"Bearer {POSTDOC_TOKEN}\"}\n",
    "POSTDOC_ID = client.get(\"/users/me\", headers=POSTDOC_AUTH).json()[\"id\"]\n",
    "print(f\"Postdoc ID: {POSTDOC_ID}\")\n",
    "\n",
    "# Add postdoc directly to the project (not via group)\n",
    "resp = client.post(f\"/api/projects/{PROJECT_ID}/members\", headers=AUTH, json={\n",
    "    \"member_type\": \"user\",\n",
    "    \"member_id\": POSTDOC_ID,\n",
    "})\n",
    "pp(resp)\n",
    "\n",
    "# Postdoc can also see the file\n",
    "resp = client.get(f\"/api/files/{FILE_ID}\", headers=POSTDOC_AUTH)\n",
    "print(f\"\\nPostdoc file access status: {resp.status_code}\")\n",
    "# Expected: 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10C-e. Projects CRUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All projects ===\n",
      "[\n",
      "  {\n",
      "    \"id\": \"9341e3af-9530-4f36-9c31-18022a05b416\",\n",
      "    \"name\": \"Kinase Inhibitor Fragment Screen\",\n",
      "    \"description\": \"High-throughput NMR fragment screening of kinase inhibitor candidates\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.537291Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.537291Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"02ae46d4-9a35-4c7a-b425-f76621f8a761\",\n",
      "    \"name\": \"HER2 Phosphoproteome Profiling\",\n",
      "    \"description\": \"Quantitative phosphoproteomics of HER2-positive breast cancer cell lines\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.554289Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.554289Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"59429056-f585-4f7d-985c-7299eb609662\",\n",
      "    \"name\": \"Gold Nanoparticle Structure Determination\",\n",
      "    \"description\": \"Atomic-resolution TEM imaging and structural analysis of AuNP catalysts\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.562575Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.562575Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"62c887c8-27a1-40a6-af37-b95fc5ec7373\",\n",
      "    \"name\": \"Multi-omics Cancer Biomarker Discovery\",\n",
      "    \"description\": \"Integrated NMR metabolomics and proteomics for cancer biomarker identification\",\n",
      "    \"created_at\": \"2026-03-01T18:50:44.570598Z\",\n",
      "    \"updated_at\": \"2026-03-01T18:50:44.570598Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"2e8af5f2-6032-4648-80bf-269f9ca7cf80\",\n",
      "    \"name\": \"Microscopy Study 2026\",\n",
      "    \"description\": \"Main research project\",\n",
      "    \"created_at\": \"2026-03-01T19:24:43.748744Z\",\n",
      "    \"updated_at\": \"2026-03-01T19:24:43.748744Z\"\n",
      "  }\n",
      "]\n",
      "\n",
      "=== Project members ===\n",
      "[\n",
      "  {\n",
      "    \"id\": \"573df377-8f42-4a46-b492-8353dc8b79c0\",\n",
      "    \"project_id\": \"2e8af5f2-6032-4648-80bf-269f9ca7cf80\",\n",
      "    \"member_type\": \"group\",\n",
      "    \"member_id\": \"36d27c20-984a-4d5d-a158-56adc48649b1\",\n",
      "    \"email\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"9a1ffc01-6eab-48dd-ae8f-8e6cd84f345c\",\n",
      "    \"project_id\": \"2e8af5f2-6032-4648-80bf-269f9ca7cf80\",\n",
      "    \"member_type\": \"user\",\n",
      "    \"member_id\": \"c22064ae-cba3-4ff0-8645-e9a6a9e5c035\",\n",
      "    \"email\": \"postdoc@test.org\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# List projects\n",
    "print(\"=== All projects ===\")\n",
    "pp(client.get(\"/api/projects\"))\n",
    "\n",
    "# List project members\n",
    "print(\"\\n=== Project members ===\")\n",
    "pp(client.get(f\"/api/projects/{PROJECT_ID}/members\"))\n",
    "# Expected: 2 members (1 group + 1 direct user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove member status: 204\n",
      "{\n",
      "  \"detail\": \"File not found\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Remove postdoc from project\n",
    "resp = client.delete(f\"/api/projects/{PROJECT_ID}/members/{POSTDOC_ID}\", headers=AUTH)\n",
    "print(f\"Remove member status: {resp.status_code}\")\n",
    "# Expected: 204\n",
    "\n",
    "# Postdoc loses access\n",
    "resp = client.get(f\"/api/files/{FILE_ID}\", headers=POSTDOC_AUTH)\n",
    "pp(resp)\n",
    "# Expected: {\"detail\": \"File not found\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10C-f. Non-admin users cannot manage groups/projects/grants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /api/groups: 403 — {'detail': 'Admin access required'}\n",
      "GET /api/projects: 403 — {'detail': 'Admin access required'}\n",
      "GET /api/files/fc38212d-4f71-405c-be81-26aa8f173beb/access: 403 — {'detail': 'Admin access required'}\n"
     ]
    }
   ],
   "source": [
    "# All of these should return 403\n",
    "for endpoint in [\"/api/groups\", \"/api/projects\", f\"/api/files/{FILE_ID}/access\"]:\n",
    "    resp = client.get(endpoint, headers=USER_AUTH)\n",
    "    print(f\"GET {endpoint}: {resp.status_code} — {resp.json()}\")\n",
    "# Expected: {\"detail\": \"Admin access required\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 11. File & Transfer API Filtering Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 11a. Filter files by instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files for instrument 4bca34e9-5309-4d8d-b78c-af9ef64845f8: 6\n"
     ]
    }
   ],
   "source": [
    "INSTRUMENT_ID = instruments[0][\"id\"]\n",
    "\n",
    "resp = client.get(f\"/api/files?instrument_id={INSTRUMENT_ID}\", headers=AUTH)\n",
    "print(f\"Files for instrument {INSTRUMENT_ID}: {len(resp.json())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11b. Filter transfers by file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"4bf5abaf-b2ed-412b-87f6-3c7326d80ba9\",\n",
      "    \"file_id\": \"fc38212d-4f71-405c-be81-26aa8f173beb\",\n",
      "    \"storage_location_id\": \"7cb0e261-f511-4ff3-96af-0bd3323d0ba7\",\n",
      "    \"destination_path\": \"/storage/archive/Microscope 01/microscope/user_a/experiment_001/scan_01.csv\",\n",
      "    \"transfer_adapter\": \"rclone\",\n",
      "    \"status\": \"completed\",\n",
      "    \"bytes_transferred\": 23,\n",
      "    \"source_checksum\": null,\n",
      "    \"dest_checksum\": \"7c0d455ba2126c3d\",\n",
      "    \"checksum_verified\": false,\n",
      "    \"started_at\": \"2026-02-24T17:06:10.730384Z\",\n",
      "    \"completed_at\": \"2026-02-24T17:06:10.790206Z\",\n",
      "    \"error_message\": null,\n",
      "    \"prefect_flow_run_id\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "FILE_ID = client.get(\"/api/files\", headers=AUTH).json()[0][\"id\"]\n",
    "\n",
    "resp = client.get(f\"/api/transfers?file_id={FILE_ID}\", headers=AUTH)\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11c. Get single file by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"fc38212d-4f71-405c-be81-26aa8f173beb\",\n",
      "  \"persistent_id\": \"ark:/99999/fk4biqspimyync43nspm5elixje3m\",\n",
      "  \"persistent_id_type\": \"ark\",\n",
      "  \"instrument_id\": \"4bca34e9-5309-4d8d-b78c-af9ef64845f8\",\n",
      "  \"source_path\": \"microscope/user_a/experiment_001/scan_01.csv\",\n",
      "  \"filename\": \"scan_01.csv\",\n",
      "  \"size_bytes\": 23,\n",
      "  \"source_mtime\": \"2026-02-24T17:05:59.485000Z\",\n",
      "  \"xxhash\": \"7c0d455ba2126c3d\",\n",
      "  \"sha256\": null,\n",
      "  \"first_discovered_at\": \"2026-02-24T17:06:10.729750Z\",\n",
      "  \"metadata_\": {\n",
      "    \"username\": \"user_a\",\n",
      "    \"experiment\": \"experiment_001\"\n",
      "  },\n",
      "  \"owner_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp = client.get(f\"/api/files/{FILE_ID}\", headers=AUTH)\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify all fields are present: `persistent_id`, `persistent_id_type`, `source_path`, `filename`, `xxhash`, `first_discovered_at`, `metadata_`.\n",
    "\n",
    "### 11d. Get single transfer by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"0866d35b-f4f2-492d-a562-2a816fd27da8\",\n",
      "  \"file_id\": \"37bc26ec-ed36-4148-ba35-e27b4b3103ac\",\n",
      "  \"storage_location_id\": \"7cb0e261-f511-4ff3-96af-0bd3323d0ba7\",\n",
      "  \"destination_path\": \"/storage/archive/Microscope 01/microscope/experiment_001.csv\",\n",
      "  \"transfer_adapter\": \"rclone\",\n",
      "  \"status\": \"completed\",\n",
      "  \"bytes_transferred\": 302,\n",
      "  \"source_checksum\": null,\n",
      "  \"dest_checksum\": \"2660dec29d8c3f7b\",\n",
      "  \"checksum_verified\": false,\n",
      "  \"started_at\": \"2026-02-24T17:06:10.399059Z\",\n",
      "  \"completed_at\": \"2026-02-24T17:06:10.458032Z\",\n",
      "  \"error_message\": null,\n",
      "  \"prefect_flow_run_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "TRANSFER_ID = client.get(\"/api/transfers\", headers=AUTH).json()[0][\"id\"]\n",
    "\n",
    "resp = client.get(f\"/api/transfers/{TRANSFER_ID}\", headers=AUTH)\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Schedule CRUD with Prefect Sync\n",
    "\n",
    "### 12a. Create a new schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"f1598bd0-af1d-403d-8713-7431e03e5ec1\",\n",
      "  \"instrument_id\": \"4bca34e9-5309-4d8d-b78c-af9ef64845f8\",\n",
      "  \"default_storage_location_id\": \"7cb0e261-f511-4ff3-96af-0bd3323d0ba7\",\n",
      "  \"cron_expression\": \"0 */6 * * *\",\n",
      "  \"prefect_deployment_id\": \"a28a83b2-4d95-45ba-acd3-6b664c9ba1e7\",\n",
      "  \"enabled\": true,\n",
      "  \"created_at\": \"2026-02-24T17:06:11.923544Z\",\n",
      "  \"updated_at\": \"2026-02-24T17:06:11.925086Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp = client.post(\"/api/schedules\", headers=AUTH, json={\n",
    "    \"instrument_id\": INSTRUMENT_ID,\n",
    "    \"default_storage_location_id\": STORAGE_ID,\n",
    "    \"cron_expression\": \"0 */6 * * *\",\n",
    "    \"enabled\": True,\n",
    "})\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `prefect_deployment_id` is populated (Prefect deployment was created)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12b. Update the schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '725fa608-f4da-40f5-980a-2aa977ffe7e3',\n",
       "  'instrument_id': '4bca34e9-5309-4d8d-b78c-af9ef64845f8',\n",
       "  'default_storage_location_id': '7cb0e261-f511-4ff3-96af-0bd3323d0ba7',\n",
       "  'cron_expression': '*/15 * * * *',\n",
       "  'prefect_deployment_id': 'a28a83b2-4d95-45ba-acd3-6b664c9ba1e7',\n",
       "  'enabled': True,\n",
       "  'created_at': '2026-02-24T17:05:41.521453Z',\n",
       "  'updated_at': '2026-02-24T17:05:41.523843Z'},\n",
       " {'id': '0293924e-a6de-459c-98c0-6d73303d576b',\n",
       "  'instrument_id': '65186f54-074d-430e-b2ca-c24b4861e990',\n",
       "  'default_storage_location_id': '7cb0e261-f511-4ff3-96af-0bd3323d0ba7',\n",
       "  'cron_expression': '*/15 * * * *',\n",
       "  'prefect_deployment_id': '97ee019b-aa52-43b0-84e9-f472b9951c50',\n",
       "  'enabled': True,\n",
       "  'created_at': '2026-02-24T17:05:42.798288Z',\n",
       "  'updated_at': '2026-02-24T17:05:42.799405Z'},\n",
       " {'id': 'a86e9e55-9518-4b9f-9a24-321f3ea3b428',\n",
       "  'instrument_id': '20bfa6b2-87a4-4d41-9c97-d7f59bd92723',\n",
       "  'default_storage_location_id': '51c43e6b-e524-4fd0-aa92-3b40d8fe7cda',\n",
       "  'cron_expression': '*/15 * * * *',\n",
       "  'prefect_deployment_id': 'decb9a53-cd72-4922-959c-9a955338e70f',\n",
       "  'enabled': True,\n",
       "  'created_at': '2026-02-24T17:05:42.839518Z',\n",
       "  'updated_at': '2026-02-24T17:05:42.840528Z'},\n",
       " {'id': 'f1598bd0-af1d-403d-8713-7431e03e5ec1',\n",
       "  'instrument_id': '4bca34e9-5309-4d8d-b78c-af9ef64845f8',\n",
       "  'default_storage_location_id': '7cb0e261-f511-4ff3-96af-0bd3323d0ba7',\n",
       "  'cron_expression': '0 */6 * * *',\n",
       "  'prefect_deployment_id': 'a28a83b2-4d95-45ba-acd3-6b664c9ba1e7',\n",
       "  'enabled': True,\n",
       "  'created_at': '2026-02-24T17:06:11.923544Z',\n",
       "  'updated_at': '2026-02-24T17:06:11.925086Z'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get(\"/api/schedules\", headers=AUTH).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"725fa608-f4da-40f5-980a-2aa977ffe7e3\",\n",
      "  \"instrument_id\": \"4bca34e9-5309-4d8d-b78c-af9ef64845f8\",\n",
      "  \"default_storage_location_id\": \"7cb0e261-f511-4ff3-96af-0bd3323d0ba7\",\n",
      "  \"cron_expression\": \"0 */12 * * *\",\n",
      "  \"prefect_deployment_id\": \"a28a83b2-4d95-45ba-acd3-6b664c9ba1e7\",\n",
      "  \"enabled\": true,\n",
      "  \"created_at\": \"2026-02-24T17:05:41.521453Z\",\n",
      "  \"updated_at\": \"2026-02-24T17:06:12.010835Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "NEW_SCHEDULE_ID = client.get(\"/api/schedules\", headers=AUTH).json()[0][\"id\"]\n",
    "\n",
    "resp = client.patch(f\"/api/schedules/{NEW_SCHEDULE_ID}\", headers=AUTH, json={\n",
    "    \"cron_expression\": \"0 */12 * * *\",\n",
    "})\n",
    "pp(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify in Prefect UI that the deployment schedule updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test Idempotent Discovery\n",
    "\n",
    "Trigger the same harvest twice — the second run should find zero new files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'725fa608-f4da-40f5-980a-2aa977ffe7e3'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCHEDULE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger 1: {'flow_run_id': '12a6ac99-7067-4e23-a245-692db7d52a42', 'schedule_id': '725fa608-f4da-40f5-980a-2aa977ffe7e3'}\n",
      "Waiting for flow run 12a6ac99-7067-4e23-a245-692db7d52a42 to complete...\n",
      "  State: SCHEDULED (attempt 1/120)\n",
      "  State: SCHEDULED (attempt 2/120)\n",
      "  State: SCHEDULED (attempt 3/120)\n",
      "  State: SCHEDULED (attempt 4/120)\n",
      "  State: SCHEDULED (attempt 5/120)\n",
      "  State: PENDING (attempt 6/120)\n",
      "  State: RUNNING (attempt 7/120)\n",
      "Flow run finished with state: COMPLETED\n",
      "Files before: 6\n",
      "\n",
      "Trigger 2: {'flow_run_id': '836fecca-bbb1-4c9a-8280-bdf253751018', 'schedule_id': '725fa608-f4da-40f5-980a-2aa977ffe7e3'}\n",
      "Waiting for flow run 836fecca-bbb1-4c9a-8280-bdf253751018 to complete...\n",
      "  State: SCHEDULED (attempt 1/120)\n",
      "  State: SCHEDULED (attempt 2/120)\n",
      "  State: SCHEDULED (attempt 3/120)\n",
      "  State: SCHEDULED (attempt 4/120)\n",
      "  State: SCHEDULED (attempt 5/120)\n",
      "  State: SCHEDULED (attempt 6/120)\n",
      "  State: SCHEDULED (attempt 7/120)\n",
      "  State: SCHEDULED (attempt 8/120)\n",
      "  State: SCHEDULED (attempt 9/120)\n",
      "  State: SCHEDULED (attempt 10/120)\n",
      "  State: PENDING (attempt 11/120)\n",
      "Flow run finished with state: COMPLETED\n",
      "Files after: 6\n",
      "\n",
      "PASS: No duplicate files\n"
     ]
    }
   ],
   "source": [
    "# First trigger\n",
    "resp = client.post(f\"/api/schedules/{SCHEDULE_ID}/trigger\", headers=AUTH)\n",
    "FLOW_RUN_ID = resp.json().get(\"flow_run_id\")\n",
    "print(\"Trigger 1:\", resp.json())\n",
    "wait_for_flow_run(FLOW_RUN_ID)\n",
    "\n",
    "before = len(client.get(\"/api/files\", headers=AUTH).json())\n",
    "print(f\"Files before: {before}\\n\")\n",
    "\n",
    "# Second trigger\n",
    "resp = client.post(f\"/api/schedules/{SCHEDULE_ID}/trigger\", headers=AUTH)\n",
    "print(\"Trigger 2:\", resp.json())\n",
    "FLOW_RUN_ID = resp.json().get(\"flow_run_id\")\n",
    "wait_for_flow_run(FLOW_RUN_ID)\n",
    "\n",
    "after = len(client.get(\"/api/files\", headers=AUTH).json())\n",
    "print(f\"Files after: {after}\\n\")\n",
    "\n",
    "if before == after:\n",
    "    print(\"PASS: No duplicate files\")\n",
    "else:\n",
    "    print(\"FAIL: Duplicate files created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7c. Check enriched metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_flow_run(METADATA_FLOW_RUN_ID)\n",
    "\n",
    "resp = client.get(\"/api/files\", headers=AUTH)\n",
    "for f in resp.json():\n",
    "    print(json.dumps({\n",
    "        \"filename\": f[\"filename\"],\n",
    "        \"source_path\": f[\"source_path\"],\n",
    "        \"metadata_\": f.get(\"metadata_\"),\n",
    "    }, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files inside dated experiment folders should have extracted metadata:\n",
    "```json\n",
    "{\n",
    "  \"filename\": \"acqus\",\n",
    "  \"source_path\": \"20260115_glucose_1H/acqus\",\n",
    "  \"metadata_\": {\n",
    "    \"date\": \"20260115\",\n",
    "    \"compound\": \"glucose\",\n",
    "    \"nucleus\": \"1H\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Cleanup\n",
    "\n",
    "Run the cell below, or from a terminal:\n",
    "\n",
    "```bash\n",
    "docker compose -f docker-compose.yml -f docker-compose.dev.yml down -v\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove test files written to the NMR instrument share\n",
    "run(f'docker compose {DEV_COMPOSE} exec samba-instruments sh -c '\n",
    "    '\"rm -rf /data/nmr/scratch.tmp /data/nmr/empty.txt /data/nmr/user_a /data/nmr/user_b 2>/dev/null; true\"')\n",
    "\n",
    "# Tear down the dev stack\n",
    "_ = run(f\"docker compose {DEV_COMPOSE} down -v\")\n",
    "\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm no containers are still running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run(f\"docker compose {DEV_COMPOSE} ps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide demonstrated the core capabilities of the **StreamWeave** backend, a research data management platform designed to automate the discovery, transfer, and governance of instrument-generated data.\n",
    "\n",
    "### Features Covered\n",
    "\n",
    "- **Automated File Discovery & Transfer** — Schedules that automatically harvest files from instrument sources, with checksum verification and idempotent processing\n",
    "- **Persistent Identifiers (ARK)** — Every discovered file receives a unique, standards-compliant ARK identifier for long-term reference\n",
    "- **Workflow Orchestration** — Prefect-powered flow execution with real-time monitoring, manual triggers, and scheduled runs\n",
    "- **Extensible Hooks System** — Pre-transfer hooks for filtering files and post-transfer hooks for metadata enrichment\n",
    "- **Fine-Grained Access Control** — User, group, and project-based permissions with hierarchical inheritance\n",
    "- **Full API Coverage** — RESTful endpoints for instruments, storage locations, schedules, files, transfers, and access management\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "StreamWeave is ideal for:\n",
    "- Research core facilities managing data from multiple scientific instruments\n",
    "- Laboratories requiring automated data archival with provenance tracking\n",
    "- Organizations needing compliant data governance with audit trails\n",
    "\n",
    "\n",
    "\n",
    "### Interested in deploying StreamWeave for your organization?\n",
    "\n",
    "For deployment assistance, custom integrations, or enterprise support, contact us at:\n",
    "\n",
    "**[https://datasophos.co/#contact](https://datasophos.co/#contact)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
