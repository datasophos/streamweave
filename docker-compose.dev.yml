services:
  # Caddy reverse proxy with local HTTPS at https://streamweave.local
  # Prerequisites (once per machine):
  #   echo '127.0.0.1 streamweave.local' | sudo tee -a /etc/hosts
  #   bash scripts/setup-dev-certs.sh   # generates cert via mkcert
  caddy:
    image: caddy:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./caddy/Caddyfile.dev:/etc/caddy/Caddyfile:ro
      - ./caddy/certs:/etc/caddy/certs:ro
      - caddy_config:/config
    depends_on:
      - api
      - frontend

  mailpit:
    image: axllent/mailpit:latest
    command: --webroot /mail/
    ports:
      - "1025:1025"   # SMTP (still needed for host-side testing tools)

  # S3-compatible object storage backed by rclone (Apache 2.0)
  # Proxied at https://streamweave.local/s3  Access key: devkey  Secret: devsecret
  s3-dev:
    image: rclone/rclone:latest
    command: >
      serve s3 /data
      --addr :9000
      --auth-key devkey,devsecret
      --vfs-cache-mode full
    volumes:
      - s3_data:/data

  # ── Instrument data sources ───────────────────────────────────────────────
  # instruments-init copies read-only sample_data/ bind-mounts into named
  # volumes so the demo notebook can write transient files without touching the
  # host filesystem.  samba-instruments then serves all 4 volumes as shares.

  instruments-init:
    image: busybox
    volumes:
      - ./dev/instruments/nmr-bruker/sample_data:/source/nmr:ro
      - ./dev/instruments/hplc-waters/sample_data:/source/hplc:ro
      - ./dev/instruments/ms-orbitrap/sample_data:/source/ms:ro
      - ./dev/instruments/tem-titan/sample_data:/source/tem:ro
      - nmr_live_data:/data/nmr
      - hplc_live_data:/data/hplc
      - ms_live_data:/data/ms
      - tem_live_data:/data/tem
    command: sh -c "for d in nmr hplc ms tem; do rm -rf /data/$$d/* /data/$$d/.[!.]* 2>/dev/null; cp -r /source/$$d/. /data/$$d/; done"
    restart: "no"

  samba-instruments:
    image: dperson/samba:latest
    command: >
      -u "devuser;devpass"
      -s "nmr;/data/nmr;yes;no;no;devuser"
      -s "hplc;/data/hplc;yes;no;no;devuser"
      -s "ms;/data/ms;yes;no;no;devuser"
      -s "tem;/data/tem;yes;no;no;devuser"
      -p
    volumes:
      - nmr_live_data:/data/nmr
      - hplc_live_data:/data/hplc
      - ms_live_data:/data/ms
      - tem_live_data:/data/tem
    ports:
      - "4461:445"
    depends_on:
      instruments-init:
        condition: service_completed_successfully

  # ── Archive destination ───────────────────────────────────────────────────
  # Separate Samba share used as the CIFS storage location target.
  samba-archive:
    image: dperson/samba:latest
    ports:
      - "445:445"
    environment:
      USER: "devuser;devpass"
      SHARE: "archive;/share;yes;no;no;devuser"
      WORKGROUP: WORKGROUP
    volumes:
      - samba_data:/share

  api:
    build:
      context: ./backend
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql+asyncpg://streamweave:streamweave@postgres:5432/streamweave
      SECRET_KEY: dev-secret-key
      STREAMWEAVE_ENCRYPTION_KEY: ${STREAMWEAVE_ENCRYPTION_KEY:-0ZSeboblFSmXLvCew5ToiQJSUcmmbMKKXG1OISVmeU0=}
      PREFECT_API_URL: http://prefect-server:4200/api
      ADMIN_EMAIL: ${ADMIN_EMAIL:-admin@example.com}
      ADMIN_PASSWORD: ${ADMIN_PASSWORD:-adminpassword}
      SMTP_HOST: mailpit
      SMTP_PORT: 1025
      SMTP_TLS: "false"
      SMTP_ENABLED: "true"
      SMTP_FROM: noreply@streamweave.local
      BCRYPT_ROUNDS: 6
    depends_on:
      postgres:
        condition: service_healthy
      prefect-server:
        condition: service_healthy
      mailpit:
        condition: service_started
    volumes:
      - ./backend:/app
      - harvest_data:/storage
    command: >
      sh -c "alembic upgrade head &&
             python ensure_admin.py &&
             uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 15s

  # Seeds realistic example data once the API is healthy.
  # Re-running is safe — existing resources are skipped.
  dev-seed:
    build:
      context: ./backend
    environment:
      API_URL: http://api:8000
      ADMIN_EMAIL: ${ADMIN_EMAIL:-admin@example.com}
      ADMIN_PASSWORD: ${ADMIN_PASSWORD:-adminpassword}
    depends_on:
      api:
        condition: service_healthy
      s3-dev:
        condition: service_started
    volumes:
      - ./dev:/seed
      - harvest_data:/storage
    command: python /seed/seed.py
    restart: "no"

  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.worker
    environment:
      DATABASE_URL: postgresql+asyncpg://streamweave:streamweave@postgres:5432/streamweave
      SECRET_KEY: dev-secret-key
      STREAMWEAVE_ENCRYPTION_KEY: ${STREAMWEAVE_ENCRYPTION_KEY:-0ZSeboblFSmXLvCew5ToiQJSUcmmbMKKXG1OISVmeU0=}
      PREFECT_API_URL: http://prefect-server:4200/api
    depends_on:
      postgres:
        condition: service_healthy
      prefect-server:
        condition: service_healthy
    volumes:
      - ./backend:/app
      - harvest_data:/storage

  # Frontend dev server with hot-reload.
  # Caddy proxies HTTPS → this Vite server; no need to expose port 3000 directly.
  # Override the production multi-stage Dockerfile with a trivial inline build so
  # the dev image is actually node:22-alpine (not the Caddy production image).
  # Using a project-scoped name avoids shadowing the public node:22-alpine image.
  # ports: [] clears the 80/443 bindings from docker-compose.yml so Caddy owns them.
  frontend:
    build:
      context: ./frontend
      dockerfile_inline: "FROM node:22-alpine"
    image: streamweave-frontend-dev
    working_dir: /app
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      VITE_API_URL: ""
      VITE_PROXY_TARGET: "http://api:8000"
      VITE_ADMIN_EMAIL: ${ADMIN_EMAIL:-admin@example.com}
      VITE_ADMIN_PASSWORD: ${ADMIN_PASSWORD:-adminpassword}
      VITE_DEMO_MODE: "true"
    command: sh -c "npm install && npm run dev -- --host 0.0.0.0"
    depends_on:
      - api

volumes:
  harvest_data:
  s3_data:
  samba_data:
  caddy_config:
  nmr_live_data:
  hplc_live_data:
  ms_live_data:
  tem_live_data:
